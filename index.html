<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Click Prompt Learning with Optimal Transport for Interactive Segmentation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Click Prompt Learning with Optimal Transport for Interactive Segmentation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jliu4ai.github.io">Jie Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Haochen Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Wenzhe Yin</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.nki.nl/research/research-groups/jan-jakob-sonke/">Jan-Jakob Sonke</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.egavves.com/">Efstratios Gavves</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Amsterdam,</span>
            <span class="author-block"><sup>2</sup>Netherlands Cancer Institute</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arxiv PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/intro.jpg"
      class="interpolation-image"
      alt="Interpolate start reference image."
      style="width: 100%; height: auto;"/>
      </div>
      <h2 class="content has-text-justified">
        <span class="content has-text-justified">In this work, we propose <strong>Click Prompt learning with Optimal Transport (CPlot)</strong> for interactive segmentation. 
           With the key component <strong>Click Prompt Optimal Transport (CPOT)</strong>, our model captures diverse user intentions, leading to more accurate mask prediction.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Click-based interactive segmentation aims to segment target objects conditioned on user-provided clicks.
            Existing methods typically interpret user intention by learning multiple click prompts to generate corresponding prompt-activated masks, and selecting one from these masks.
            However, directly matching each prompt to the same visual feature often leads to homogeneous prompt-activated masks, as it pushes the click prompts to converge to one point. 
          </p>
          <p>
            To address this problem, we propose Click Prompt Learning with Optimal Transport (CPlot), which leverages optimal transport theory to capture diverse user intentions with multiple click prompts. 
            Specifically, we first introduce a prompt-pixel alignment module (PPAM), which aligns each click prompts with the visual features in the same feature space by plain transformer blocks. 
            In such way, PPAM enables all click prompts to encode more general knowledge about regions of interest, indicating a consistent user intention.
          </p>
          <p>
            To capture diverse user intentions, we further propose the click prompt optimal transport module (CPOT) to match click prompts and visual features.
            CPOT is designed to learn an optimal mapping between click prompts and visual features. Such unique mapping facilities click prompts to effectively focus on distinct visual regions, which reflect underlying diverse user intentions.
            Furthermore, CPlot learns click prompts with a two-stage optimization strategy: the inner loop optimizes the optimal transport distance to align visual features with click prompts through the Sinkhorn algorithm, while the outer loop adjusts the click prompts from the supervised data.
          </p>
          <p>
            Extensive experiments on eight interactive segmentation benchmarks demonstrate the superiority of our method for interactive segmentation
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!--/ Method. -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-header">
          <h2 class="title is-3 has-text-centered method-title">Method</h2>
        </div>
        <div class="hero-body">
          <img src="./static/images/method.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."
          style="width: 100%; height: auto;"/>
          </div>
          <h2 class="content has-text-justified">
            <span class="content has-text-justified">Framework of <strong>Click Prompt Learning with Optimal Transport (CPlot)</strong>. Given input image, click disk maps, and previous mask, 
              the Image Encoder extracts visual features. The Click Encoder initializes click prompts with click coordinates. (a) <strong>The Prompt-Pixel Alignment Module</strong> aims to align click prompts with the visual features in the feature space. 
              (b) <strong>Click Prompt Optimal Transport</strong> adopts optimal transport plan to generate optimized mask from vanilla prompt-activated mask. A lightweight mask decoder is used to implicitly analyze optimized prompt-activated mask with visual features and make mask predictions.
          </h2>
        </div>
      </div>
    </section>
    <!--/ Method. -->

  </div>
</section>

<!--/ citation. -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It borrows the source code from <a
              href="https://github.com/nerfies/nerfies.github.io">this website</a>. We would like to thank Utkarsh Sinha and Keunhong Park.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
